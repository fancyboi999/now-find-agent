from loguru import logger
from sqlalchemy import event, text
from sqlalchemy.ext.asyncio import async_sessionmaker, create_async_engine
from sqlalchemy.pool import Pool

# å»¶è¿Ÿè·å–é…ç½®ï¼Œé¿å…åœ¨æ¨¡å—å¯¼å…¥æ—¶å°±åˆå§‹åŒ–
def get_settings():
    from config.config import get_settings as _get_settings
    return _get_settings()

# åˆå§‹é…ç½®ï¼ˆé»˜è®¤å€¼ï¼‰
settings = None

# ä»DATABASE_URLä¸­æå–schemaä¿¡æ¯
def extract_schema_from_url(database_url: str) -> str:
    """ä»æ•°æ®åº“URLä¸­æå–schemaåç§°

    ä¼˜å…ˆä» URL çš„ options ä¸­çš„ search_path æå–ï¼›
    å¦‚æœªæä¾›ï¼Œåˆ™å›é€€ä¸ºä½¿ç”¨æ•°æ®åº“åä½œä¸º schema åï¼ˆä¸ç°æœ‰åº“ä¸€è‡´çš„çº¦å®šï¼‰ã€‚
    """
    import urllib.parse

    try:
        parsed = urllib.parse.urlparse(database_url)
        query_params = urllib.parse.parse_qs(parsed.query)

        # å¤„ç† options=-c search_path=schema_name æ ¼å¼
        if "options" in query_params:
            options = query_params["options"][0]
            if "search_path=" in options:
                schema = options.split("search_path=")[1].split(",")[0].strip()
                logger.info(f"ä»URLä¸­æå–åˆ°schema: {schema}")
                return schema

        # å›é€€ï¼šä½¿ç”¨æ•°æ®åº“åä½œä¸º schema å
        db_name = parsed.path.lstrip("/") or "public"
        logger.info(f"ä»æ•°æ®åº“åå›é€€å¾—åˆ°schema: {db_name}")
        return db_name
    except Exception as parse_error:
        logger.warning(f"è§£æDATABASE_URLè·å–schemaå¤±è´¥ï¼Œå›é€€ä¸ºpublic: {parse_error}")
        return "public"


# NOW Find Agent æ•°æ®åº“é…ç½® - å»¶è¿Ÿåˆå§‹åŒ–
def get_database_url():
    """å»¶è¿Ÿè·å–æ•°æ®åº“URLï¼Œç¡®ä¿Nacosé…ç½®å·²åŠ è½½"""
    settings = get_settings()
    if not settings.DATABASE_URL:
        logger.info("DATABASE_URLæœªé…ç½®ï¼Œä½¿ç”¨é»˜è®¤çš„SQLiteæ•°æ®åº“")
        return "sqlite+aiosqlite:///./app.db"
    else:
        logger.info(f"é…ç½®çš„æ•°æ®åº“URLæˆåŠŸ")
        return settings.DATABASE_URL

# åˆå§‹åŒ–å˜é‡ï¼Œä½†å»¶è¿Ÿèµ‹å€¼
DATABASE_URL = None


# TODO: æ•°æ®åº“è¿æ¥äº‹ä»¶ç›‘å¬å™¨å°†åœ¨å˜é‡å®šä¹‰åè®¾ç½®


# å¤šæ•°æ®åº“æ”¯æŒ - æ™ºèƒ½æ£€æµ‹å’ŒURLæ ¼å¼åŒ–
def detect_database_type(url: str) -> str:
    """æ£€æµ‹æ•°æ®åº“ç±»å‹"""
    url_lower = url.lower()
    if any(db in url_lower for db in ["mysql", "mariadb"]):
        return "mysql"
    elif any(db in url_lower for db in ["postgresql", "postgres"]):
        return "postgresql"
    elif "sqlite" in url_lower:
        return "sqlite"
    else:
        return "unknown"

def format_database_url(url: str) -> str:
    """æ ¼å¼åŒ–æ•°æ®åº“URLä¸ºæ­£ç¡®çš„å¼‚æ­¥é©±åŠ¨æ ¼å¼"""
    if not url:
        return url
        
    db_type = detect_database_type(url)
    
    # å¦‚æœå·²ç»æ˜¯æ­£ç¡®çš„å¼‚æ­¥æ ¼å¼ï¼Œç›´æ¥è¿”å›
    if any(driver in url for driver in ["aiomysql", "asyncpg", "aiosqlite"]):
        return url
    
    # æ ¹æ®æ•°æ®åº“ç±»å‹ä¿®æ­£é©±åŠ¨
    if db_type == "mysql":
        if url.startswith("mysql://"):
            url = url.replace("mysql://", "mysql+aiomysql://", 1)
            logger.info("ğŸ”„ ä¿®æ­£MySQL URLä¸ºå¼‚æ­¥é©±åŠ¨æ ¼å¼: mysql+aiomysql://")
        elif url.startswith("jdbc:mysql://"):
            # JDBC URLè½¬æ¢ä¸ºSQLAlchemyæ ¼å¼
            jdbc_url = url.replace("jdbc:mysql://", "mysql+aiomysql://")
            # ç®€åŒ–å‚æ•°ï¼Œç§»é™¤JDBCç‰¹æœ‰çš„å‚æ•°
            import urllib.parse
            parsed = urllib.parse.urlparse(jdbc_url)
            query_params = urllib.parse.parse_qs(parsed.query)
            # ä¿ç•™åŸºæœ¬å‚æ•°ï¼Œç§»é™¤JDBCç‰¹æœ‰å‚æ•°
            safe_params = {k: v for k, v in query_params.items() 
                          if k not in ['statementInterceptors', 'useUnicode']}
            new_query = urllib.parse.urlencode(safe_params, doseq=True)
            url = urllib.parse.urlunparse((
                parsed.scheme, parsed.netloc, parsed.path,
                parsed.params, new_query, parsed.fragment
            ))
            logger.info("ğŸ”„ è½¬æ¢JDBC MySQL URLä¸ºå¼‚æ­¥æ ¼å¼")
    elif db_type == "postgresql":
        if url.startswith("postgresql://"):
            url = url.replace("postgresql://", "postgresql+asyncpg://", 1)
            logger.info("ğŸ”„ ä¿®æ­£PostgreSQL URLä¸ºå¼‚æ­¥é©±åŠ¨æ ¼å¼: postgresql+asyncpg://")
    elif db_type == "sqlite":
        if url.startswith("sqlite://"):
            url = url.replace("sqlite://", "sqlite+aiosqlite://", 1)
            logger.info("ğŸ”„ ä¿®æ­£SQLite URLä¸ºå¼‚æ­¥é©±åŠ¨æ ¼å¼: sqlite+aiosqlite://")
    
    return url


# å»¶è¿Ÿè·å–æ•°æ®åº“é…ç½®
def get_database_config():
    """å»¶è¿Ÿè·å–æ•°æ®åº“é…ç½®ï¼Œç¡®ä¿Nacosé…ç½®å·²åŠ è½½"""
    global DATABASE_URL, CLEANED_DATABASE_URL, DB_TYPE, SCHEMA_NAME, ENGINE_CONNECT_ARGS
    
    if DATABASE_URL is None:
        DATABASE_URL = get_database_url()
        CLEANED_DATABASE_URL = format_database_url(DATABASE_URL)
        DB_TYPE = detect_database_type(CLEANED_DATABASE_URL)
        SCHEMA_NAME = extract_schema_from_url(CLEANED_DATABASE_URL)
        ENGINE_CONNECT_ARGS = build_connection_args(DB_TYPE, SCHEMA_NAME)
    
    return {
        "DATABASE_URL": DATABASE_URL,
        "CLEANED_DATABASE_URL": CLEANED_DATABASE_URL,
        "DB_TYPE": DB_TYPE,
        "SCHEMA_NAME": SCHEMA_NAME,
        "ENGINE_CONNECT_ARGS": ENGINE_CONNECT_ARGS
    }

# åˆå§‹åŒ–å˜é‡
CLEANED_DATABASE_URL = None
DB_TYPE = None
SCHEMA_NAME = None
ENGINE_CONNECT_ARGS = None

# æ™ºèƒ½æ„å»ºæ•°æ®åº“è¿æ¥å‚æ•°
def build_connection_args(db_type: str, schema_name: str) -> dict:
    """æ ¹æ®æ•°æ®åº“ç±»å‹æ„å»ºè¿æ¥å‚æ•°"""
    if db_type == "postgresql":
        return {
            "server_settings": {
                "application_name": "now-find-agent",
                "search_path": f"{schema_name},public",
            },
            "command_timeout": 60,
        }
    elif db_type == "mysql":
        return {
            "connect_timeout": 60,
            "autocommit": False,
        }
    elif db_type == "sqlite":
        return {
            "check_same_thread": False,  # SQLiteå¼‚æ­¥éœ€è¦
        }
    else:
        return {}

# å»¶è¿Ÿè®¾ç½®æ•°æ®åº“è¿æ¥äº‹ä»¶ç›‘å¬å™¨
def setup_database_event_listeners():
    """è®¾ç½®æ•°æ®åº“è¿æ¥äº‹ä»¶ç›‘å¬å™¨"""
    config = get_database_config()
    db_type = config["DB_TYPE"]
    cleaned_url = config["CLEANED_DATABASE_URL"]
    schema_name = config["SCHEMA_NAME"]
    
    if db_type == "postgresql" and "asyncpg" not in cleaned_url:
        # åªå¯¹éasyncpgçš„PostgreSQLè¿æ¥è®¾ç½®search_path
        @event.listens_for(Pool, "connect")
        def set_postgres_search_path(dbapi_connection, connection_record):
            """ä¸ºPostgreSQLæ–°è¿æ¥è®¾ç½®search_path"""
            try:
                cursor = dbapi_connection.cursor()
                cursor.execute(f"SET search_path TO {schema_name}, public")
                cursor.close()
                logger.debug(f"ğŸ”§ PostgreSQLè¿æ¥è®¾ç½®search_path: {schema_name}")
            except Exception as e:
                logger.warning(f"âš ï¸ PostgreSQLè®¾ç½®search_pathå¤±è´¥: {e}")
    elif db_type == "mysql":
        # MySQLè¿æ¥åˆå§‹åŒ–ï¼ˆå¦‚æœéœ€è¦ç‰¹æ®Šè®¾ç½®ï¼‰
        @event.listens_for(Pool, "connect")
        def set_mysql_settings(dbapi_connection, connection_record):
            """ä¸ºMySQLè¿æ¥è®¾ç½®ç‰¹æ®Šå‚æ•°"""
            try:
                cursor = dbapi_connection.cursor()
                # è®¾ç½®MySQLç‰¹å®šå‚æ•°ï¼ˆå¦‚å­—ç¬¦é›†ã€æ—¶åŒºç­‰ï¼‰
                cursor.execute("SET NAMES utf8mb4")
                cursor.execute("SET time_zone = '+00:00'")
                cursor.close()
                logger.debug(f"ğŸ”§ MySQLè¿æ¥åˆå§‹åŒ–å®Œæˆ")
            except Exception as e:
                logger.warning(f"âš ï¸ MySQLè¿æ¥åˆå§‹åŒ–å¤±è´¥: {e}")
    # SQLiteä¸éœ€è¦ç‰¹æ®Šçš„è¿æ¥è®¾ç½®


""" å¼‚æ­¥å¼•æ“

https://blog.csdn.net/meisanggou/article/details/104427146

pool_size
è®¾ç½®è¿æ¥æ± ä¸­, ä¿æŒçš„è¿æ¥æ•°. åˆå§‹åŒ–æ—¶, å¹¶ä¸äº§ç”Ÿè¿æ¥. åªæœ‰æ…¢æ…¢éœ€è¦è¿æ¥æ—¶, æ‰ä¼šäº§ç”Ÿè¿æ¥. ä¾‹å¦‚æˆ‘ä»¬çš„è¿æ¥æ•°è®¾ç½®æˆpool_size=10. å¦‚æœæˆ‘ä»¬çš„å¹¶å‘é‡ä¸€ç›´æœ€é«˜æ˜¯5. é‚£ä¹ˆæˆ‘ä»¬çš„è¿æ¥æ± é‡Œçš„è¿æ¥æ•°ä¹Ÿå°±æ˜¯5. å½“æˆ‘ä»¬æœ‰ä¸€æ¬¡å¹¶å‘é‡è¾¾åˆ°äº†10. ä»¥åå¹¶å‘é‡è™½ç„¶ä¸‹å»äº†, è¿æ¥æ± ä¸­ä¹Ÿä¼šä¿æŒ10ä¸ªè¿æ¥.

max_overflow
å½“è¿æ¥æ± é‡Œçš„è¿æ¥æ•°å·²è¾¾åˆ°, pool_sizeæ—¶, ä¸”éƒ½è¢«ä½¿ç”¨æ—¶. åˆè¦æ±‚ä»è¿æ¥æ± é‡Œè·å–è¿æ¥æ—¶, max_overflowå°±æ˜¯å…è®¸å†æ–°å»ºçš„è¿æ¥æ•°.
ä¾‹å¦‚pool_size=10, max_overflow=5. å½“æˆ‘ä»¬çš„å¹¶å‘é‡è¾¾åˆ°12æ—¶, å½“ç¬¬11ä¸ªå¹¶å‘åˆ°æ¥å, å°±ä¼šå»å†å»ºä¸€ä¸ªè¿æ¥, ç¬¬12ä¸ªåŒæ ·. å½“ç¬¬11ä¸ªè¿æ¥å¤„ç†å®Œå›æ”¶å, è‹¥æ²¡æœ‰åœ¨ç­‰å¾…è¿›ç¨‹è·å–è¿æ¥, è¿™ä¸ªè¿æ¥å°†ä¼šè¢«ç«‹å³é‡Šæ”¾.

pool_timeout
ä»è¿æ¥æ± é‡Œè·å–è¿æ¥, å¦‚æœæ­¤æ—¶æ— ç©ºé—²çš„è¿æ¥. ä¸”è¿æ¥æ•°å·²ç»åˆ°è¾¾äº†pool_size+max_overflow. æ­¤æ—¶è·å–è¿æ¥çš„è¿›ç¨‹ä¼šç­‰å¾…pool_timeoutç§’. å¦‚æœè¶…è¿‡è¿™ä¸ªæ—¶é—´, è¿˜æ²¡æœ‰è·å¾—å°†ä¼šæŠ›å‡ºå¼‚å¸¸.
sqlalchemyé»˜è®¤30ç§’

pool_recycle
è¿™ä¸ªæŒ‡, ä¸€ä¸ªæ•°æ®åº“è¿æ¥çš„ç”Ÿå­˜æ—¶é—´. ä¾‹å¦‚pool_recycle=3600. ä¹Ÿå°±æ˜¯å½“è¿™ä¸ªè¿æ¥äº§ç”Ÿ1å°æ—¶å, å†è·å¾—è¿™ä¸ªè¿æ¥æ—¶, ä¼šä¸¢å¼ƒè¿™ä¸ªè¿æ¥, é‡æ–°åˆ›å»ºä¸€ä¸ªæ–°çš„è¿æ¥.
å½“pool_recycleè®¾ç½®ä¸º-1æ—¶, ä¹Ÿå°±æ˜¯è¿æ¥æ± ä¸ä¼šä¸»åŠ¨ä¸¢å¼ƒè¿™ä¸ªè¿æ¥. æ°¸ä¹…å¯ç”¨. ä½†æ˜¯æœ‰å¯èƒ½æ•°æ®åº“serverè®¾ç½®äº†è¿æ¥è¶…æ—¶æ—¶é—´. ä¾‹å¦‚mysql, è®¾ç½®çš„æœ‰wait_timeouté»˜è®¤ä¸º28800, 8å°æ—¶. å½“è¿æ¥ç©ºé—²8å°æ—¶æ—¶ä¼šè‡ªåŠ¨æ–­å¼€. 8å°æ—¶åå†ç”¨è¿™ä¸ªè¿æ¥ä¹Ÿä¼šè¢«é‡ç½®.
"""
# å»¶è¿Ÿåˆ›å»ºå¼•æ“å’Œä¼šè¯å·¥å‚
def get_engine():
    """å»¶è¿Ÿåˆ›å»ºæ•°æ®åº“å¼•æ“"""
    global engine, async_session
    
    if engine is None:
        config = get_database_config()
        
        # é¦–å…ˆè®¾ç½®äº‹ä»¶ç›‘å¬å™¨
        setup_database_event_listeners()
        
        logger.info(f"ğŸ”§ æ•°æ®åº“ç±»å‹: {config['DB_TYPE'].upper()}, è¿æ¥å‚æ•°å·²é…ç½®")
        
        engine = create_async_engine(
            config["CLEANED_DATABASE_URL"],  # ä½¿ç”¨æ¸…ç†åçš„æ•°æ®åº“URL
            echo=False,  # æ˜¯å¦æ‰“å°å‡ºå®é™…æ‰§è¡Œçš„ sql, è°ƒè¯•çš„æ—¶å€™å¯èƒ½æ›´æ–¹ä¾¿
            future=True,  # ä½¿ç”¨ SQLAlchemy 2.0 API, å‘åå…¼å®¹
            max_overflow=15,  # å½“è¿æ¥æ± é‡Œçš„è¿æ¥æ•°å·²è¾¾åˆ° pool_size ä¸”éƒ½è¢«ä½¿ç”¨æ—¶,
            pool_size=8,  # æ¥æ± ä¸­ä¿æŒçš„è¿æ¥æ•°, è®¾ç½®ä¸º 0 æ—¶è¡¨ç¤ºè¿æ¥æ— é™åˆ¶
            pool_recycle=60 * 15,  # 15 minutes, è®¾ç½®æ—¶é—´ä»¥é™åˆ¶æ•°æ®åº“è‡ªåŠ¨æ–­å¼€
            pool_timeout=30.0,  # å¦‚æœè¶…è¿‡è¿™ä¸ªæ—¶é—´, è¿˜æ²¡æœ‰è·å¾—å°†ä¼šæŠ›å‡ºå¼‚å¸¸
            pool_pre_ping=True,  # å¯ç”¨è¿æ¥é¢„æ£€æŸ¥,åœ¨ä½¿ç”¨è¿æ¥å‰å…ˆpingæ•°æ®åº“
            pool_reset_on_return="commit",  # è¿æ¥è¿”å›æ± æ—¶é‡ç½®çŠ¶æ€
            connect_args=config["ENGINE_CONNECT_ARGS"],
        )
        async_session = async_sessionmaker(
            bind=engine,
            expire_on_commit=False,  # session.commit ä¹‹åä»ç„¶å¯ä»¥æŸ¥è¯¢è¯¥å¯¹è±¡
        )
    
    return engine, async_session

# åˆå§‹åŒ–å˜é‡
engine = None
async_session = None


async def check_database_health():
    """å¤šæ•°æ®åº“å¥åº·æ£€æŸ¥ - æ™ºèƒ½é€‚é…ä¸åŒæ•°æ®åº“ç±»å‹"""
    try:
        engine, async_session = get_engine()
        config = get_database_config()
        
        async with async_session() as session:
            # åŸºæœ¬è¿æ¥æµ‹è¯• - æ‰€æœ‰æ•°æ®åº“éƒ½æ”¯æŒ
            await session.execute(text("SELECT 1"))
            
            # æ ¹æ®æ•°æ®åº“ç±»å‹æ‰§è¡Œç‰¹å®šæ£€æŸ¥
            if config["DB_TYPE"] == "postgresql":
                # PostgreSQLç‰¹æœ‰æ£€æŸ¥
                result = await session.execute(text("SHOW search_path"))
                search_path = result.scalar()
                logger.debug(f"PostgreSQL search_path: {search_path}")
            elif config["DB_TYPE"] == "mysql":
                # MySQLç‰¹æœ‰æ£€æŸ¥
                result = await session.execute(text("SELECT DATABASE()"))
                db_name = result.scalar()
                logger.debug(f"MySQLå½“å‰æ•°æ®åº“: {db_name}")
            elif config["DB_TYPE"] == "sqlite":
                # SQLiteç‰¹æœ‰æ£€æŸ¥
                result = await session.execute(text("PRAGMA database_list"))
                db_info = result.fetchall()
                logger.debug(f"SQLiteæ•°æ®åº“åˆ—è¡¨: {len(db_info)} ä¸ªæ•°æ®åº“")
            
        logger.info(f"âœ… {config['DB_TYPE'].upper()} æ•°æ®åº“å¥åº·æ£€æŸ¥é€šè¿‡")
        return True
    except Exception as e:
        logger.error(f"âŒ æ•°æ®åº“å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
        return False


async def get_database_pool_status():
    """è·å–æ•°æ®åº“è¿æ¥æ± çŠ¶æ€ä¿¡æ¯"""
    try:
        engine, _ = get_engine()
        pool = engine.pool
        status = {
            "size": pool.size(),
            "checked_in": pool.checkedin(),
            "checked_out": pool.checkedout(),
            "overflow": pool.overflow(),
        }

        # å°è¯•è·å–invalidçŠ¶æ€,å¦‚æœä¸å­˜åœ¨åˆ™è·³è¿‡
        try:
            status["invalid"] = pool.invalid()
        except AttributeError:
            # AsyncAdaptedQueuePool æ²¡æœ‰ invalid() æ–¹æ³•
            logger.debug("è¿æ¥æ± ä¸æ”¯æŒinvalid()æ–¹æ³•,è·³è¿‡è¯¥çŠ¶æ€æ£€æŸ¥")

        return status
    except Exception as e:
        logger.error(f"è·å–è¿æ¥æ± çŠ¶æ€å¤±è´¥: {e}")
        return None


# å…¨å±€å˜é‡ç”¨äºæ”¯æŒåŠ¨æ€é‡æ–°åˆå§‹åŒ–
_initialized = False

async def initialize_database():
    """åŠ¨æ€åˆå§‹åŒ–æ•°æ®åº“è¿æ¥ï¼ˆæ”¯æŒé…ç½®å˜æ›´åçš„é‡æ–°åˆå§‹åŒ–ï¼‰"""
    global _initialized, DATABASE_URL, CLEANED_DATABASE_URL, DB_TYPE, SCHEMA_NAME, ENGINE_CONNECT_ARGS, engine, async_session
    
    try:
        # å¦‚æœå·²ç»åˆå§‹åŒ–è¿‡ï¼Œå…ˆå…³é—­æ—§è¿æ¥
        if _initialized and engine is not None:
            try:
                await engine.dispose()
                logger.info("æ—§çš„æ•°æ®åº“è¿æ¥å·²å…³é—­")
            except Exception as e:
                logger.warning(f"å…³é—­æ—§æ•°æ®åº“è¿æ¥æ—¶å‡ºé”™: {e}")
        
        # é‡ç½®æ‰€æœ‰å…¨å±€å˜é‡ï¼Œå¼ºåˆ¶é‡æ–°åŠ è½½é…ç½®
        DATABASE_URL = None
        CLEANED_DATABASE_URL = None
        DB_TYPE = None
        SCHEMA_NAME = None
        ENGINE_CONNECT_ARGS = None
        engine = None
        async_session = None
        
        # è·å–æ–°çš„é…ç½®å’Œå¼•æ“
        config = get_database_config()
        engine, async_session = get_engine()
        
        _initialized = True
        logger.info(f"âœ… æ•°æ®åº“é‡æ–°åˆå§‹åŒ–æˆåŠŸ: {config['DB_TYPE'].upper()}")
        logger.info(f"ğŸ”§ æ•°æ®åº“ç±»å‹: {config['DB_TYPE'].upper()}, è¿æ¥å‚æ•°å·²é…ç½®")
        
        # æµ‹è¯•è¿æ¥
        await check_database_health()
        
    except Exception as e:
        logger.error(f"âŒ æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")
        raise


# å¯¼å‡ºåˆå§‹åŒ–å‡½æ•°
__all__ = [
    "engine", "async_session", "DB_TYPE", "SCHEMA_NAME", "CLEANED_DATABASE_URL",
    "check_database_health", "get_database_pool_status", "initialize_database",
    "get_database_url", "get_database_config", "get_engine"
]
